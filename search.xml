<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>你的模型运行快吗？</title>
      <link href="/2018/12/05/model-computation/"/>
      <url>/2018/12/05/model-computation/</url>
      
        <content type="html"><![CDATA[<blockquote><p>模型占用的存储空间、模型运行时消耗的内存空间、模型运行的速度</p></blockquote><h1 id="1-CNN不同层的计算量"><a href="#1-CNN不同层的计算量" class="headerlink" title="1. CNN不同层的计算量"></a>1. CNN不同层的计算量</h1><p>了解模型计算量的一种简单方法就是计算这个模型总共做了多少次浮点运算。除了计算量，内存带宽也是影响计算效率的重要因素。  </p><h2 id="1-1-乘积相加"><a href="#1-1-乘积相加" class="headerlink" title="1.1 乘积相加"></a>1.1 乘积相加</h2><p>神经网络中的绝大多数操作都是浮点数的乘法进行求和。例如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = w[0]*x[0] + w[1]*x[1] + w[2]*x[2] + ... + w[n-1]*x[n-1]</span><br></pre></td></tr></table></figure></p><p>上式中，输入 <code>w</code> 和 <code>x</code> 是两个向量，输出 <code>y</code> 是一个标量 ( 实数 )。在神经网络的卷积层和全连接层中， <code>w</code> 是层学习到的参数，<code>x</code> 就是层的输入，而 <code>y</code> 则是层的输出的一部分，因为典型的层结构有多个输出。其中 <code>w[0]*x[0] + ...</code> 称为一次 <a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation" target="_blank" rel="noopener">乘积相加操作(multiply-accumulate operations)</a>, 因此两个 <code>n</code> 维向量的点积含有 <code>n</code> 个 MACCs(乘积相加) 计算单元。</p><blockquote><p>Technically speaking there are only n - 1 additions in the above formula, one less than the number of multiplications. Think of the number of MACCs as being an approximation, just like Big-O notation is an approximation of the complexity of an algorithm.</p></blockquote><p>从每秒浮点运算 ( floating point operations per second, FLOPS ) 的角度来看，一次点积操作包含 <code>2n-1</code> 个 FLOPS，因为其中含有 <code>n</code> 次乘法运算和 <code>n-1</code> 次加法运算。</p><h2 id="1-2-全连接层"><a href="#1-2-全连接层" class="headerlink" title="1.2 全连接层"></a>1.2 全连接层</h2><p>在全连接层，所有的输入单元和输出单元相互连接。对于含有 <code>I</code> 个输入值和 <code>J</code> 个输出值的的层，权重 <code>W</code> 存储在 <code>I×J</code> 的矩阵中，因此全连接层的计算可以写作：<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">y</span> = matmul(x, W) + b</span><br></pre></td></tr></table></figure></p><p>矩阵乘法是有一系列点乘组合而成的。每一个点乘由输入 <code>x</code> 和矩阵<code>W</code> 的每一列运算得到。因此运算 <code>matmul(x, W)</code> 包含 <code>I×J</code> 个 MACCs 单元，和权重矩阵的元素个数相同。例如卷积层的最后输出为 <code>(512, 7, 7)</code>, 那么经过 <code>faltten</code> 操作后，输入 <code>I=512x7x7</code>。</p><h2 id="1-3-激活函数"><a href="#1-3-激活函数" class="headerlink" title="1.3 激活函数"></a>1.3 激活函数</h2><p>通常层的后面会跟随非线性激活函数，例如 ReLU 或者 sigmoid 函数。由于激活函数没有乘法运算，因此使用 FLOPS 来衡量计算时间。<br>不同激活函数的计算量是不同的。ReLU 激活函数的表达式为：<br><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">y</span> = max(x, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><p>在 GPU 上只有一次操作。假设全连接层有 <code>J</code> 个输出单元，ReLU函数进行了 <code>J</code> 次最大值操作，因此含有 <code>J</code> 个 FLOPS 单元。<br>Sigmoid 激活函数表达式为：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = <span class="number">1</span> / (<span class="number">1</span> + exp(<span class="name">-x</span>))</span><br></pre></td></tr></table></figure></p><p>由于 Sigmoid 函数包含幂运算，因此计算量比较复杂。通常将加法运算、减法运算、乘法运算、除法运算、幂运算和平方根运算称为一次 FLOPS。Sigmoid 函数中包含四种不同的运算操作，因此含有 4 次 FLOPS。假设全连接层有 <code>J</code> 个输出单元，那么Sigmoid 函数含有 <code>4xJ</code> 个 FLOPS 单元。通常激活函数只占模型总运算量的很小一部分。</p><h2 id="1-3-卷积层"><a href="#1-3-卷积层" class="headerlink" title="1.3 卷积层"></a>1.3 卷积层</h2><p>卷积层的输入和输出不是向量，而是三维 ( <code>Height*Width*Channels</code> ) 的特征图。假定正方形的卷积核边长为 <code>k</code>，那么卷积层不考虑偏置和激活函数的 MACCs 为：<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k × k × Channels<span class="number">_</span><span class="keyword">in</span> × Height<span class="number">_</span><span class="keyword">out</span> × Width<span class="number">_</span><span class="keyword">out</span> × Channels<span class="number">_</span><span class="keyword">out</span></span><br></pre></td></tr></table></figure></p><p>这里使用输出的 <code>Height</code> 和 <code>Width</code> 是因为考虑到卷积时的<code>stride, dilation factors, padding, etc</code>。<br>对于卷积核为为 <code>(3, 3, 128)</code> 且输入为 <code>(112, 112, 64)</code> 的卷积计算， 它的 MACCs 为：<br><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">3 </span>× <span class="number">3</span> × <span class="number">64</span> × <span class="number">112</span> × <span class="number">112</span> × <span class="number">128</span> = <span class="number">924844032</span></span><br></pre></td></tr></table></figure></p><blockquote><p>In this example, we used “same” padding and stride = 1, so that the output feature map has the same size as the input feature map. It’s also common to see convolutional layers use stride = 2, which would have chopped the output feature map size in half, and we would’ve used 56 × 56 instead of 112 × 112 in the above calculation.</p></blockquote><h2 id="1-4-深度可分离卷积"><a href="#1-4-深度可分离卷积" class="headerlink" title="1.4 深度可分离卷积"></a>1.4 深度可分离卷积</h2><p>深度可分离卷积 ( depthwise-separable convolution ) 首先在 <a href="https://arxiv.org/abs/1610.02357" target="_blank" rel="noopener">Xception</a> 中被使用，它将常规的卷积操作分解为 depthwise 卷积与 pointwise 卷积两个部分。该结构和常规提取特征的卷积操作类似，但是参数量和运算成本较低，在轻量级网络 ( <a href="https://arxiv.org/abs/1704.04861" target="_blank" rel="noopener">MobileNet</a> )中十分常见。  </p><p>假设输入层为 <code>(112, 112, 64)</code>，经过 <code>(3, 3, 128)</code>的卷积核，假定使用 <code>same padding</code> 并且 <code>stride=1</code>，使得输入输出特征图大小相同，那么最终得到 <code>(112, 112, 128)</code> 的特征图。常规卷积示意图如下所示。 MACCs 次数为：<br><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">3 </span>× <span class="number">3</span> × <span class="number">64</span> × <span class="number">112</span> × <span class="number">112</span> × <span class="number">128</span> = <span class="number">924844032</span></span><br></pre></td></tr></table></figure></p><div align="center"><img src="/2018/12/05/model-computation/convolution.png" alt="卷积示意图" width="400" height="300"></div><p>Depthwise Convolution 的每个卷积核只与输入的一个通道进行卷积，卷积核的数量与上一层的通道数相同。因此输入图像经过 depthwise 卷积之后生成 3 个单通道的特征图，如下图所示。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MACCs = K × K × Channels_in × Height_out × Width_out</span><br><span class="line">      = <span class="number">3</span> × <span class="number">3</span> × <span class="number">64</span> × <span class="number">112</span> × <span class="number">112</span> </span><br><span class="line">      = <span class="number">7225344</span></span><br></pre></td></tr></table></figure></p><div align="center"><img src="/2018/12/05/model-computation/depthwise_convolution.png" alt="卷积示意图" width="400" height="300"></div><p>Depthwise Convolution 完成后的特征图数量与输入层的通道数相同，无法扩展特征图的数量，而且无法有效利用不同通道在相同空间位置上的特征信息。因此在 depthwise 卷积之后需要 pointwise Convolution 将特征图进行组合生成新的特征图。Pointwise Convolution 的卷积核大小为 <code>1x1</code>。<br><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MACCs = <span class="number">1</span> × <span class="number">1</span> × Channels_in × Height_out × Width_out x Channels_out</span><br><span class="line">      = <span class="number">1</span> × <span class="number">1</span> × <span class="number">64</span> × <span class="number">112</span> × <span class="number">112</span> x <span class="number">128</span> </span><br><span class="line">      = <span class="number">102760448</span></span><br></pre></td></tr></table></figure></p><div align="center"><img src="/2018/12/05/model-computation/pointwise_convolution.png" alt="卷积示意图" width="400" height="300"></div><p>因此 depthwise-separable convolution 的 MACCs 为：<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MACCs = (K × K × Channels<span class="number">_</span><span class="keyword">in</span> × Height<span class="number">_</span><span class="keyword">out</span> × Width<span class="number">_</span><span class="keyword">out</span>) + (Channels<span class="number">_</span><span class="keyword">in</span> × Height<span class="number">_</span><span class="keyword">out</span> × Width<span class="number">_</span><span class="keyword">out</span> × Channels<span class="number">_</span><span class="keyword">out</span>) </span><br><span class="line">      = Channels<span class="number">_</span><span class="keyword">in</span> × Height<span class="number">_</span><span class="keyword">out</span> × Width<span class="number">_</span><span class="keyword">out</span> × (K × K + Channel<span class="number">_</span><span class="keyword">out</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>The exact factor is <code>K × K × Cout / (K × K + Cout)</code> . It should be pointed out that depthwise convolutions sometimes have a <code>stride &gt; 1</code>, which reduces the dimensions of their output feature map. But a pointwise layer usually has <code>stride = 1</code>, and so its output feature map will always have the same dimensions as the depthwise layer’s.</p></blockquote><h2 id="1-5-批量归一化层"><a href="#1-5-批量归一化层" class="headerlink" title="1.5 批量归一化层"></a>1.5 批量归一化层</h2><p>批量归一化层 ( Batch normalization Layer) 每一个输出的函数表达式可以写为：<br><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = gamma * (<span class="name">y</span> - mean) / sqrt(<span class="name">variance</span> + epsilon) + beta</span><br></pre></td></tr></table></figure></p><p>其中 <code>y</code> 是上一层输出特征图的一个元素，mean 为均值，variance 为方差，epsilon 确保分母不为0，gamma为尺度因子，beta 为偏置。每一个通道都有其对应的值，因此对于通道为 <code>c</code> 的卷积输出层，batch normalization layer 学习的参数量为 <code>4c</code>。<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = gamma * ((x<span class="string">[0]</span>*w<span class="string">[0]</span> + x<span class="string">[1]</span>*w<span class="string">[1]</span> + ... + x<span class="string">[n-1]</span>*w<span class="string">[n-1]</span> + b) - mean) / sqrt(variance + epsilon) + beta</span><br></pre></td></tr></table></figure></p><p>由于在预测过程中移除了 batch normlization layer，因此考虑模型的计算量时可以不用关注正则化层的影响。</p><blockquote><p> This trick only works when the order of the layers is: convolution, batch norm, ReLU — but not when it is: convolution, ReLU, batch norm. The ReLU is a non-linear operation, which messes up the math.</p></blockquote><h2 id="1-6-池化层"><a href="#1-6-池化层" class="headerlink" title="1.6 池化层"></a>1.6 池化层</h2><p>对于 <code>112, 112, 128)</code> 的特征图，如果最大池化的 <code>pooling size = 2</code> 并且 <code>stride = 2</code>，那么 FLOPS 操作数为 <code>112 × 112 × 128 = 1605632</code>。可以看到，池化层的操作数远远少于卷积层的操作数，因此池化层也是网络计算复杂度的舍入误差。</p><h1 id="2-模型耗费的内存"><a href="#2-模型耗费的内存" class="headerlink" title="2. 模型耗费的内存"></a>2. 模型耗费的内存</h1><p>在模型的每一层计算中，硬件设备需要从主存储中读取输入向量或者特征图的值，从主存储中读取权重参数并与输入计算点积，将得到的新向量或者特征图作为结果写入主存储中。这些操作都涉及到大量的内存读写，耗费的时间可能远远大于计算的次数。</p><h2 id="2-1-权重的内存"><a href="#2-1-权重的内存" class="headerlink" title="2.1 权重的内存"></a>2.1 权重的内存</h2><p>层将权重保存在主存储中，这意味着权重参数越少，模型运行速度越快。如前文所述，输入为 <code>I</code> 个神经元和输出为 <code>J</code> 个神经元之间的权重参数为 <code>I x J</code>，加上偏置向量，总的参数为 <code>( I + 1) x J</code>。对于大小为 <code>k</code>，输入通道数为 <code>Channels_in</code>，输出通道数为 <code>Channels_out</code> 的卷积层的参数为 <code>k x k Channels_in x Channels_out</code> 加上偏置向量参数 <code>Channels_out</code>。<br>对于输入 <code>4096</code> 输出为 <code>4096</code>的全连接层，其权重参数量为 <code>(4096 + 1) x 4096 = 16781312</code>。对于输入为 <code>(64, 64, 32)</code> 卷积核为 <code>(3, 3, 48)</code> 的卷积层，其权重参数量为 <code>(3 x 3 x 32 x 48 + 48 = 13872)</code>。可以看到，相比于卷积层，全连接层的参数量相对更多。</p><blockquote><p>Fully-connected and convolutional layers are actually very similar. A convolutional layer is basically a fully-connected layer with the vast majority of the connections set to 0 — each output is only connected to K × K inputs rather than all of them, and all the outputs use the same values for these connections. This is why convolutional layers are so much more efficient about memory, since they don’t store the weights for connections that are not used.</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    <entry>
      <title>Centos7使用Docker快速搭建深度学习环境</title>
      <link href="/2018/12/04/docker-env/"/>
      <url>/2018/12/04/docker-env/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是-Docker"><a href="#1-什么是-Docker" class="headerlink" title="1. 什么是 Docker"></a>1. 什么是 Docker</h1><blockquote><p>解决 “在我的机器上可以正常工作，为什么在你的机器上不能工作” 的问题。  </p></blockquote><p>随着深度学习技术的飞速发展，各种深度学习框架都有大量的粉丝。如何在一台电脑上安装多个深度学习框架？同一深度学习框架的不同版本依赖于不同的GPU版本，但是一台服务器只可能安装唯一版本的GPU。当多名开发人员在统一服务器上使用不同的深度学习框架进行开发时，往往会产生环境冲突。最好的解决方案就是采用虚拟技术。  </p><p><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a> 是世界领先的软件容器平台，也是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。而且 Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。和虚拟机相比，由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。  </p><blockquote><p>虚拟机通常用于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。</p></blockquote><h1 id="2-安装-Docker"><a href="#2-安装-Docker" class="headerlink" title="2. 安装 Docker"></a>2. 安装 <a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">Docker</a></h1><p>(a) 安装依赖包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y yum-utils device-mapper-persistent-data</span><br></pre></td></tr></table></figure></p><p>(b) 配置稳定仓库<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p><p>(c) 安装(默认为最新版)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install docker-ce</span><br></pre></td></tr></table></figure></p><p>(4) 修改docker运行时的根目录, 解决存储不足的问题<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vim /lib/systemd/system/docker.service </span><br><span class="line"><span class="comment"># 在 ExecStart=/usr/bin/dockerd 后添加 --graph=/home/docker</span></span><br><span class="line">$ ExecStart=/usr/bin/dockerd --graph=/home/docker</span><br></pre></td></tr></table></figure></p><p>(5) 重新启动docker服务<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl daemon-reload</span><br><span class="line">$ systemctl status docker</span><br><span class="line">$ systemctl start docker</span><br></pre></td></tr></table></figure></p><p>(7) 测试Docker是否正确安装<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$  docker version</span><br><span class="line">$  docker run hello-world</span><br></pre></td></tr></table></figure></p><h1 id="3-安装-nvidia-docker"><a href="#3-安装-nvidia-docker" class="headerlink" title="3. 安装 nvidia-docker"></a>3. 安装 <a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="noopener">nvidia-docker</a></h1><p>深度学习框架需要使用 GPU 加入计算，如果不安装 nvidia-docker 工具，那么在容器中将会无法调用宿主机上的 GPU 硬件设备。  </p><p>(a) 移除旧版本 nvidia-GPU 和已经存在的 GPU 容器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls -q -f driver=nvidia-docker | xargs -r -I&#123;&#125; -n1 docker ps -q -a -f volume=&#123;&#125; | xargs -r docker rm -f</span><br><span class="line">$ sudo yum remove nvidia-docker</span><br></pre></td></tr></table></figure></p><p>(b) 安装依赖包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ distribution=$(. /etc/os-release;<span class="built_in">echo</span> <span class="variable">$ID</span><span class="variable">$VERSION_ID</span>)</span><br><span class="line">$ curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.repo | \ sudo tee /etc/yum.repos.d/nvidia-docker.repo</span><br></pre></td></tr></table></figure></p><p>(c) 安装nvidia-docker<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install -y nvidia-docker2</span><br><span class="line">$ sudo pkill -SIGHUP dockerd</span><br></pre></td></tr></table></figure></p><p>(d) 测试 nvidia-docker 是否安装成功<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi</span><br></pre></td></tr></table></figure></p><h1 id="4-CUDA9-CUDNN7-python3-6-源码安装-Caffe、Caffe2、Tensorflow、-Detectron-和-Darknet"><a href="#4-CUDA9-CUDNN7-python3-6-源码安装-Caffe、Caffe2、Tensorflow、-Detectron-和-Darknet" class="headerlink" title="4. CUDA9-CUDNN7-python3.6 源码安装 Caffe、Caffe2、Tensorflow、 Detectron 和 Darknet"></a>4. CUDA9-CUDNN7-python3.6 源码安装 Caffe、Caffe2、Tensorflow、 Detectron 和 Darknet</h1><p>(a) 启动 GPU container 并登录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-docker run -tid --name TestMyGPU --net=<span class="string">'host'</span> nvidia/cuda:9.0-cudnn7-devel-centos7 /bin/bash <span class="comment"># 启动容器</span></span><br><span class="line">$ docker <span class="built_in">exec</span> -it TestMyGPU /bin/bash <span class="comment"># 登录容器</span></span><br></pre></td></tr></table></figure></p><p>(b) 配置变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> http_proxy=http://xx.xx.xx.xx:8080 <span class="comment"># 设置网络</span></span><br><span class="line">$ <span class="built_in">export</span> https_proxy=https://xx.xx.xx.xx:8080</span><br><span class="line">$ <span class="built_in">export</span> PYINSTALL=/usr/<span class="built_in">local</span>/python3 <span class="comment"># 设置python3.6安装路径</span></span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PYINSTALL</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p><p>(c) 安装 python3.6 和 Caffe，参照上一篇博客 <code>Centos7 安装 Caffe</code>。</p><p>(d) 在 <code>/home</code> 下安装 Caffe2、Tensorflow、 Detectron 和 Darknet</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖包和 opencv</span></span><br><span class="line">$ yum install -y cmake3 &amp;&amp; pip3 install cython opencv-python==3.4.2.16</span><br><span class="line"><span class="comment"># 安装 nccl，GPU分布式通信函数库</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/NVIDIA/nccl.git </span><br><span class="line">$ <span class="built_in">cd</span> nccl &amp;&amp; make -j8 src.build CUDA_HOME=<span class="string">'/usr/local/cuda-9.0/'</span> NVCC_GENCODE=<span class="string">"-gencode=arch=compute_70,code=sm_70"</span> </span><br><span class="line">$ yum install -y rpm-build rpmdevtools &amp;&amp; make -j8 pkg.redhat.build &amp;&amp; make install </span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib'</span> &gt;&gt; /root/.bashrc </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf nccl &amp;&amp; <span class="built_in">source</span>  ~/.bashrc </span><br><span class="line"><span class="comment"># 验证nccl是否安装成功</span></span><br><span class="line"><span class="comment"># cd /home &amp;&amp; git clone https://github.com/NVIDIA/nccl-tests.git \</span></span><br><span class="line"><span class="comment"># cd nccl-tests &amp;&amp; make -j8 &amp;&amp; ./build/all_reduce_perf -b 8 -e 256M -f 2 -g 1 \</span></span><br><span class="line"><span class="comment"># cd /home &amp;&amp; rm -rf nccl-tests</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 darknet</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/pjreddie/darknet.git &amp;&amp; <span class="built_in">cd</span> darknet \</span><br><span class="line"><span class="comment"># 修改 Makefile 文件，令 GPU=1，CUDNN=1，OPENCV=1</span></span><br><span class="line">$ sed -i <span class="string">'s/GPU=0/GPU=1/'</span> Makefile </span><br><span class="line">$ sed -i <span class="string">'s/CUDNN=0/CUDNN=1/'</span> Makefile </span><br><span class="line">$ sed -i <span class="string">'s/OPENCV=0/OPENCV=1/'</span> Makefile </span><br><span class="line">$ make -j32</span><br><span class="line"><span class="comment"># 验证 darknet 是否安装成功</span></span><br><span class="line"><span class="comment"># 执行 ./darknet 输出 usage: ./darknet &lt;function&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Tensorflow 和 Keras</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; pip3 install tensorflow-gpu==1.10 keras==2.2.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装caffe2</span></span><br><span class="line">$ pip3 install pyyaml future hypothesis pydot </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/pytorch/pytorch.git </span><br><span class="line">$ <span class="built_in">cd</span> pytorch &amp;&amp; git submodule update --init --recursive </span><br><span class="line"><span class="comment"># 解决编译时 cmake 的版本问题：</span></span><br><span class="line"><span class="comment"># 将文件 `pytorch/tools/build_pytorch_libs.sh` 复制到 `/home` 路径下</span></span><br><span class="line"><span class="comment"># 修改./tools/build_pytorch_libs.sh 第31和32行 CMAKE_VERSION、CMAKE3_VERSION</span></span><br><span class="line"><span class="comment"># CMAKE_VERSION=$(cmake --version | grep 'version' | awk '&#123;print $3&#125;' | awk -F. '&#123;print $1"."$2"."$3&#125;')</span></span><br><span class="line"><span class="comment"># CMAKE3_VERSION=$(cmake3 --version | grep 'version' | awk '&#123;print $3&#125;' | awk -F. '&#123;print $1"."$2"."$3&#125;')</span></span><br><span class="line">$ rm -f /home/pytorch/tools/build_pytorch_libs.sh</span><br><span class="line">$ cp -f /home/build_pytorch_libs.sh /home/pytorch/tools/build_pytorch_libs.sh</span><br><span class="line">$ rm -f /home/build_pytorch_libs.sh </span><br><span class="line">$ python setup.py install </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf pytorch</span><br></pre></td></tr></table></figure><p>验证 caffe2 是否安装成功， python 命令窗口执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> caffe2</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>exit()</span><br></pre></td></tr></table></figure></p><p>验证是否能使用 GPU<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; python -c <span class="string">'from caffe2.python import core'</span> 2&gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">"Success"</span> || <span class="built_in">echo</span> <span class="string">"Failure"</span></span><br><span class="line">$ python -c <span class="string">'from caffe2.python import workspace; print(workspace.NumCudaDevices())'</span></span><br><span class="line">$ python /usr/<span class="built_in">local</span>/anaconda3/lib/python3.6/site-packages/caffe2/python/operator_test/rnn_cell_test.py</span><br></pre></td></tr></table></figure></p><p>安装 COCO-API<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span>  https://github.com/pdollar/coco </span><br><span class="line">$ pip3 install setuptools==18.4 &amp;&amp; yum install -y tkinter</span><br><span class="line">$ <span class="built_in">cd</span> coco/PythonAPI &amp;&amp; make -j8 &amp;&amp; make install &amp;&amp; python setup.py install </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf coco</span><br></pre></td></tr></table></figure></p><p>验证 coco-api 是否安装成功, python命令窗口执行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br></pre></td></tr></table></figure></p><p>安装detectron<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/facebookresearch/detectron </span><br><span class="line">$ <span class="built_in">cd</span> detectron &amp;&amp; make -j8 </span><br><span class="line"><span class="comment"># 验证 detectron 是否正确安装</span></span><br><span class="line">$ <span class="built_in">cd</span> /home/detectron &amp;&amp; python detectron/tests/test_spatial_narrow_as_op.py</span><br><span class="line">$ python tools/infer_simple.py \</span><br><span class="line">    --cfg configs/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml \</span><br><span class="line">    --output-dir tmp/detectron-visualizations \</span><br><span class="line">    --image-ext jpg \</span><br><span class="line">    --wts https://s3-us-west-2.amazonaws.com/detectron/35861858/12_2017_baselines/e2e_mask_rcnn_R-101-FPN_2x.yaml.02_32_51.SgT4y1cO/output/train/coco_2014_train:coco_2014_valminusminival/generalized_rcnn/model_final.pkl \</span><br><span class="line">    demo</span><br></pre></td></tr></table></figure></p><h1 id="5-使用-Anaconda3-安装-Caffe、Pytorch-和-Tensorflow"><a href="#5-使用-Anaconda3-安装-Caffe、Pytorch-和-Tensorflow" class="headerlink" title="5. 使用 Anaconda3 安装 Caffe、Pytorch 和 Tensorflow"></a>5. 使用 Anaconda3 安装 Caffe、Pytorch 和 Tensorflow</h1><p><a href="https://www.anaconda.com/" target="_blank" rel="noopener">Anaconda</a> 是一个开源的Python发行版本，包含了conda、Python等180多个科学包及其依赖项，是当前最流行的 Python 数据科学开发平台。 因为包含了大量的科学包，Anaconda 的下载文件比较大（约 531 MB），如果只需要某些包，或者需要节省带宽或存储空间，也可以使用 <a href="https://conda.io/miniconda.html" target="_blank" rel="noopener">Miniconda</a> 发行版 ( 仅包含 conda 和 Python )。</p><div align="center"><img src="/2018/12/04/docker-env/anaconda.png" alt="anaconda wesite image" width="500" height="300"></div><p>Anaconda 当前集成了 caffe 和 pytorch，可以利用 Anaconda 快速安装 caffe 和 caffe2 ( 集成在 pytorch ) 中。由于 Docker 容器需要应用程序占用内存尽可能小，因此采用 Miniconda 代替 Anaconda。完成的 Dockerfile 文件如下，在宿主机中含有 <code>Dockfile</code> 文件的当前路径下运行 <code>docker build -t deep_learning_environment:v0.1 .</code> 即可生成满足深度学习环境对应要求的镜像。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">FROM nvidia/cuda:9.0-cudnn7-runtime-centos7</span><br><span class="line"></span><br><span class="line">ENV LANG=en_US.UTF-8</span><br><span class="line">ARG http_proxy=http://xx.xx.xx.xx:8080</span><br><span class="line">ARG https_proxy=https://xx.xx.xx.xx:8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装Miniconda3</span></span><br><span class="line">RUN <span class="built_in">cd</span> /home \</span><br><span class="line">    <span class="comment"># 安装依赖包</span></span><br><span class="line">    &amp;&amp; yum install -y epel-release-7-11.noarch wget git make bzip2 &amp;&amp; pip install cython \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 安装nccl</span></span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/NVIDIA/nccl.git \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> nccl &amp;&amp; make -j8 src.build CUDA_HOME=<span class="string">'/usr/local/cuda-9.0/'</span> NVCC_GENCODE=<span class="string">"-gencode=arch=compute_70,code=sm_70"</span> \</span><br><span class="line">    &amp;&amp; yum install -y rpm-build rpmdevtools &amp;&amp; make -j8 pkg.redhat.build &amp;&amp; make install \</span><br><span class="line">    &amp;&amp; <span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/nccl/build/lib'</span> &gt;&gt; /root/.bashrc \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /home &amp;&amp; rm -rf nccl &amp;&amp; <span class="built_in">source</span>  ~/.bashrc \</span><br><span class="line">    <span class="comment"># 验证nccl是否安装成功</span></span><br><span class="line">    <span class="comment"># cd /home &amp;&amp; git clone https://github.com/NVIDIA/nccl-tests.git \</span></span><br><span class="line">    <span class="comment"># cd nccl-tests &amp;&amp; make -j8 &amp;&amp; ./build/all_reduce_perf -b 8 -e 256M -f 2 -g 1 \</span></span><br><span class="line">    <span class="comment"># cd /home &amp;&amp; rm -rf nccl-tests</span></span><br><span class="line"></span><br><span class="line">    &amp;&amp; wget https://repo.anaconda.com/miniconda/Miniconda3-4.3.30-Linux-x86_64.sh \</span><br><span class="line">    &amp;&amp; bash Miniconda3-4.3.30-Linux-x86_64.sh -p /usr/<span class="built_in">local</span>/miniconda3 -b \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将 miniconda 添加到系统路径</span></span><br><span class="line">    &amp;&amp; <span class="built_in">echo</span> <span class="string">'export PATH=/usr/local/miniconda3/bin:$PATH'</span> &gt;&gt; /root/.bashrc \</span><br><span class="line">    &amp;&amp; <span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=/usr/local/miniconda3/lib:$LD_LIBRARY_PATH'</span> &gt;&gt; /root/.bashrc \</span><br><span class="line">    &amp;&amp; <span class="built_in">source</span>  ~/.bashrc &amp;&amp; rm -rf Miniconda3-4.3.30-Linux-x86_64.sh \</span><br><span class="line">    <span class="comment"># 修改yum的链接问题</span></span><br><span class="line">    &amp;&amp; ln -s -f /usr/lib64/liblzma.so.5 /usr/<span class="built_in">local</span>/miniconda3/lib/liblzma.so.5 \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># conda 安装 caffe-gpu</span></span><br><span class="line">    &amp;&amp; conda install -y caffe-gpu protobuf \</span><br><span class="line">    <span class="comment"># conda 安装 caffe2</span></span><br><span class="line">    <span class="comment"># 直接安装下载速度非常慢，而且有可能失败</span></span><br><span class="line">    &amp;&amp; conda install -y pytorch-nightly -c pytorch \</span><br><span class="line">    &amp;&amp; pip install future hypothesis pydot \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证 caffe 和 caffe2 是否安装成功</span></span><br><span class="line">    <span class="comment"># $ python &amp;&amp; import torch &amp;&amp; import caffe &amp;&amp; import caffe2</span></span><br><span class="line">    <span class="comment"># python -c 'from caffe2.python import core' 2&gt;/dev/null &amp;&amp; echo "Success" || echo "Failure"</span></span><br><span class="line">    <span class="comment"># python -c 'from caffe2.python import workspace; print(workspace.NumCudaDevices())'</span></span><br><span class="line">    <span class="comment"># python /usr/local/anaconda3/lib/python3.6/site-packages/caffe2/python/operator_test/rnn_cell_test.py</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 安装 detectron</span></span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/facebookresearch/detectron \</span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> detectron &amp;&amp; pip install cython &amp;&amp; make -j8 \</span><br><span class="line">    <span class="comment"># 验证 detectron 是否安装正确</span></span><br><span class="line">    <span class="comment"># cd /home/detectron &amp;&amp; python detectron/tests/test_spatial_narrow_as_op.py</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 安装darknet, 从 github 上下载darknet源码, 修改 Makefile 文件，令 GPU=1，CUDNN=1，OPENCV=1。</span></span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/pjreddie/darknet.git &amp;&amp; <span class="built_in">cd</span> darknet \</span><br><span class="line">    &amp;&amp; sed -i <span class="string">'s/GPU=0/GPU=1/'</span> Makefile \</span><br><span class="line">    &amp;&amp; sed -i <span class="string">'s/CUDNN=0/CUDNN=1/'</span> Makefile \</span><br><span class="line">    &amp;&amp; sed -i <span class="string">'s/OPENCV=0/OPENCV=1/'</span> Makefile \</span><br><span class="line">    &amp;&amp; make -j8 \</span><br><span class="line">    <span class="comment"># 验证 darknet 是否安装成功</span></span><br><span class="line">    <span class="comment"># 执行 ./darknet 输出 usage: ./darknet &lt;function&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 安装tensorflow和keras</span></span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /home &amp;&amp; pip install tensorflow-gpu==1.10 keras==2.2.0 -i https://pypi.douban.com/simple/ \</span><br><span class="line">    <span class="comment"># 验证 tensorflow 和 keras 是否安装成功</span></span><br><span class="line">    <span class="comment"># $ python &amp;&amp; import tensorflow &amp;&amp; import keras</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除 minicond3/pkgs 里面的安装包, 降低内存占用</span></span><br><span class="line">    &amp;&amp; <span class="built_in">cd</span> /usr/<span class="built_in">local</span>/miniconda3/ &amp;&amp; rm -rf pkgs</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 安装教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centoe7 深度学习环境 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Centos7 安装 Caffe</title>
      <link href="/2018/12/03/centos-caffe/"/>
      <url>/2018/12/03/centos-caffe/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Caffe-是什么"><a href="#1-Caffe-是什么" class="headerlink" title="1. Caffe 是什么"></a>1. Caffe 是什么</h1><p><a href="http://caffe.berkeleyvision.org/" target="_blank" rel="noopener">Caffe</a> 全称 Convolutional Architecture for Fast Feature Embedding，是一种常用的深度学习框架，主要应用在视频、图像处理方面的应用上。得益于RCNN框架的影响力，当前主流的目标检测模型 ( 例如 <a href="https://github.com/ShaoqingRen/faster_rcnn" target="_blank" rel="noopener">Faster-RCNN</a> 和 <a href="https://github.com/weiliu89/caffe" target="_blank" rel="noopener">SSD</a> ) 的作者源码都是基于 Caffe 编写的。</p><h1 id="2-Centos7-安装-Caffe"><a href="#2-Centos7-安装-Caffe" class="headerlink" title="2. Centos7 安装 Caffe"></a>2. Centos7 安装 Caffe</h1><p>虽然网上已经有很多相关的安装教程，但是大多数都是基于 Ubantu 系统的，而且网上的教程在安装过程中往往会报出各种莫名其妙的 bug。经过笔者多次血泪实践，发现大多数错误都是因为未能正确安装 boost 和 protouf 工具包。假设 Centos7 已经正确安装 Nvidia GPU 驱动程序和 CUDA9+CUDNN7的加速包，按照如下教程即可正确编译 Caffe 的 Python3.6 接口。如果电脑没有安装 GPU 驱动，请先参照 Nvidia <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="noopener">官网安装教程</a> 正确安装 GPU。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装依赖包</span></span><br><span class="line">$ yum clean all &amp;&amp; yum makecache &amp;&amp; yum install -y epel-release-7-11.noarch </span><br><span class="line">$ yum -y install zlib-devel openssl-devel bzip2-devel expat-devel</span><br><span class="line">$ yum -y install gdbm-devel readline-devel sqlite-devel</span><br><span class="line">$ yum -y install wget git make unzip libSM libXrender libXext</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Python3.6</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tgz</span><br><span class="line">$ tar -xvf Python-3.6.6.tgz &amp;&amp; <span class="built_in">cd</span> Python-3.6.6</span><br><span class="line">$ ./configure --prefix=<span class="variable">$PYINSTALL</span> &amp;&amp; make -j32 &amp;&amp; make install</span><br><span class="line">$ ln -s <span class="variable">$PYINSTALL</span>/bin/python3 <span class="variable">$PYINSTALL</span>/bin/python</span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf Python-3.6.6.tgz Python-3.6.6</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 scikit-image</span></span><br><span class="line">$ pip3 install numpy scikit-image -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com </span><br><span class="line"><span class="comment"># 安装 caffe 依赖包</span></span><br><span class="line">$ yum -y install leveldb-devel snappy-devel opencv-devel hdf5-devel </span><br><span class="line">$ yum -y install gflags-devel glog-devel lmdb-devel openblas-devel python36-devel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译 boost 修复 libboost_python3.so 无法连接的错误</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; wget https://dl.bintray.com/boostorg/release/1.67.0/<span class="built_in">source</span>/boost_1_67_0.tar.gz </span><br><span class="line">$ tar -xvf boost_1_67_0.tar.gz </span><br><span class="line">$ <span class="built_in">cd</span> boost_1_67_0 &amp;&amp; ./bootstrap.sh --with-toolset=gcc </span><br><span class="line">$ ./b2 cflags=<span class="string">'-fPIC'</span> cxxflags=<span class="string">'-fPIC'</span> include=/usr/include/python3.6m &amp;&amp; ./b2 install </span><br><span class="line">$ ln -s /usr/<span class="built_in">local</span>/lib/libboost_python36.so /usr/lib64/libboost_python3.so </span><br><span class="line">$ <span class="built_in">echo</span> /usr/<span class="built_in">local</span>/lib &gt;&gt; /etc/ld.so.conf.d/caffe.conf &amp;&amp; ldconfig </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf boost_1_67_0.tar.gz boost_1_67_0 </span><br><span class="line"></span><br><span class="line"> <span class="comment"># 安装 protobuf</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib'</span> &gt;&gt; /root/.bashrc </span><br><span class="line">$ <span class="built_in">source</span>  ~/.bashrc</span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; wget https://github.com/protocolbuffers/protobuf/releases/download/v3.5.1/protobuf-cpp-3.5.1.zip </span><br><span class="line">$ unzip protobuf-cpp-3.5.1.zip </span><br><span class="line">$ <span class="built_in">cd</span> protobuf-3.5.1 &amp;&amp; ./configure &amp;&amp; make -j32 &amp;&amp; make install </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf protobuf-cpp-3.5.1.zip protobuf-3.5.1 </span><br><span class="line">$ wget https://github.com/protocolbuffers/protobuf/releases/download/v3.5.1/protobuf-python-3.5.1.zip </span><br><span class="line">$ unzip protobuf-python-3.5.1.zip </span><br><span class="line">$ <span class="built_in">cd</span> protobuf-3.5.1/python &amp;&amp; python setup.py build &amp;&amp; python setup.py install </span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; rm -rf protobuf-python-3.5.1.zip protobuf-3.5.1</span><br></pre></td></tr></table></figure></p><p>安装 caffe， 需要修改配置文件 <code>Makefile.config</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 caffe</span></span><br><span class="line">$ <span class="built_in">cd</span> /home &amp;&amp; git <span class="built_in">clone</span> https://github.com/bvlc/caffe.git</span><br><span class="line"><span class="comment"># 将 caffe/Makefile.config.example 文件复制到 /home 路径下，命名为 Makefile.config 并进行修改</span></span><br><span class="line"><span class="comment"># 第05行改为 USE_CUDNN := 1</span></span><br><span class="line"><span class="comment"># 第11行改为 USE_OPENCV := 1</span></span><br><span class="line"><span class="comment"># 第39行改为 CUDA_ARCH :=-gencode arch=compute_30,code=sm_30 \</span></span><br><span class="line"><span class="comment"># 第51行改为 BLAS := open</span></span><br><span class="line"><span class="comment"># 第55行改为 BLAS_INCLUDE := /usr/include/openblas</span></span><br><span class="line"><span class="comment"># 第56行改为 BLAS_LIB := /usr/lib64</span></span><br><span class="line">$ cp Makefile.config caffe/Makefile.config &amp;&amp; rm -f Makefile.config</span><br><span class="line">$ <span class="built_in">cd</span> caffe &amp;&amp; make -j32 &amp;&amp; make pycaffe -j32</span><br><span class="line">$ cp -r python/caffe /usr/<span class="built_in">local</span>/python3/lib/python3.6/site-packages</span><br><span class="line">$ cp .build_release/lib/* /usr/lib64</span><br></pre></td></tr></table></figure></p><p>在 <code>python</code> 命令窗口中执行 <code>import caffe</code> 查看 caffe 的 python 接口是否编译成功。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 验证 caffe 是否安装成功</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> caffe</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> 安装教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos caffe python3 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World——利用hexo和github快速搭建个人博客</title>
      <link href="/2018/12/01/hello-world/"/>
      <url>/2018/12/01/hello-world/</url>
      
        <content type="html"><![CDATA[<h2 id="一、hexo和github简介"><a href="#一、hexo和github简介" class="headerlink" title="一、hexo和github简介"></a>一、hexo和github简介</h2><blockquote><p>Hexo 生成静态网页，Github 托管网页，Markdown 编辑博客。</p></blockquote><h3 id="1-hexo是什么？"><a href="#1-hexo是什么？" class="headerlink" title="1. hexo是什么？"></a>1. hexo是什么？</h3><p><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> 是一款基于 Node.js 语言、快速、简洁且高效的博客框架。通过使用Markdown（或其他渲染引擎）解析文章，即使是前端小白也可利用 hexo 框架的靓丽主题快速生成相当专业的静态网页。</p><h3 id="2-github是什么？"><a href="#2-github是什么？" class="headerlink" title="2. github是什么？"></a>2. github是什么？</h3><p><a href="https://github.com/explore" target="_blank" rel="noopener">GitHub</a> 是一个面向开源及私有软件项目的托管平台，除了git 代码仓库托管及基本的 Web 管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能，是当前最活跃的“程序猿交友平台”。</p><h3 id="3-markdown是什么？"><a href="#3-markdown是什么？" class="headerlink" title="3. markdown是什么？"></a>3. markdown是什么？</h3><p><a href="http://www.markdown.cn/" target="_blank" rel="noopener">Markdown</a> 是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。Markdown的语法简洁易学，功能比纯文本更强大，世界上最流行的博客平台 WordPress 能很好的支持Markdown。</p><h2 id="二、搭建博客环境"><a href="#二、搭建博客环境" class="headerlink" title="二、搭建博客环境"></a>二、搭建博客环境</h2><h3 id="1-安装-Node-js"><a href="#1-安装-Node-js" class="headerlink" title="1. 安装 Node.js"></a>1. 安装 Node.js</h3><p>Hexo 博客框架基于 Node.js 语言，首先下载 <a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node.js安装包</a>，选择对应的版本进行安装。默认安装过程会配置环境变量及 npm 包，安装完成后在命令窗口（例如 windows 系统的 cmd 窗口）输入 <code>node -v</code> 即可验证是否安装成功。</p><h3 id="2-安装-Git"><a href="#2-安装-Git" class="headerlink" title="2. 安装 Git"></a>2. 安装 Git</h3><p>Git 是开源的分布式版本控制系统，可以将本地编辑完成的博客同步到 Github 服务器上。首先下载 <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">Git安装包</a>，安装完成后在命令窗口输入 <code>git -v</code> 即可验证是否安装成功。</p><h3 id="3-安装-Hexo"><a href="#3-安装-Hexo" class="headerlink" title="3. 安装 Hexo"></a>3. 安装 Hexo</h3><p>Hexo是个人博客网站的框架，安装步骤参考 <a href="https://hexo.io/zh-cn/docs/" target="_blank" rel="noopener">官网文档</a>。首先在本地建立名为blog的文件夹（文件夹名任意），然后在blog文件夹当前路径下开启命令窗口，通过 npm 命令即可完成安装。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p><p>安装完成后，在命令窗口中初始化博客。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init blog</span><br></pre></td></tr></table></figure></p><p>初始化完成后，分别下述命令检测博客环境是否正常。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate       <span class="comment"># 生成博客</span></span><br><span class="line">$ hexo server         <span class="comment"># 启动本地服务器</span></span><br></pre></td></tr></table></figure></p><p>hexo 3.0把服务器独立成个别模块，需要单独安装<code>npm i hexo-server</code>。如果没有报错，接下来就是见证奇迹的时刻了。在浏览器中输入网址 <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>，就可以看到诞生的第一篇博客。</p><h3 id="4-上传到-Github"><a href="#4-上传到-Github" class="headerlink" title="4. 上传到 Github"></a>4. 上传到 Github</h3><p>首先到 <a href="https://github.com/" target="_blank" rel="noopener">官网注册</a>，假定注册的用户名为 user_name，注册的邮箱为 user_email，然后创建一个仓库，设置该仓库的主页面，得到你的github主页面网址 <a href="http://user_name.github.io" target="_blank" rel="noopener">http://user_name.github.io</a>。其他用户在浏览器中输入该网址，就能看到你的主页面。最后编辑站点配置文件 <code>/blog/_config.yml</code>，在该文件的末尾加入：<br><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">deploy</span>:</span><br><span class="line">  <span class="attribute">type</span>: git</span><br><span class="line">  <span class="attribute">repository</span>: <span class="attribute">https</span>:<span class="comment">//github.com/user_name/user_name.github.io</span></span><br><span class="line">  <span class="attribute">branch</span>: master</span><br></pre></td></tr></table></figure></p><p>在命令窗口运行代码 <code>npm install hexo-deployer-git --save</code> 安装 git 命令部署插件后，执行如下代码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name <span class="string">"user_name"</span>     <span class="comment"># 指定 git 上传的仓库</span></span><br><span class="line">$ git config --global user.email user_email</span><br><span class="line"></span><br><span class="line">$ hexo clean             <span class="comment"># 清理缓存</span></span><br><span class="line">$ hexo generate          <span class="comment"># 生成博客</span></span><br><span class="line">$ hexo deploy            <span class="comment"># 同步到 github 主页面</span></span><br></pre></td></tr></table></figure></p><h3 id="5-绑定个人域名"><a href="#5-绑定个人域名" class="headerlink" title="5. 绑定个人域名"></a>5. 绑定个人域名</h3><p>待续</p><h3 id="6-图床加速"><a href="#6-图床加速" class="headerlink" title="6. 图床加速"></a>6. 图床加速</h3><p>待续</p><h3 id="7-Markdown-编辑工具"><a href="#7-Markdown-编辑工具" class="headerlink" title="7. Markdown 编辑工具"></a>7. Markdown 编辑工具</h3><p>当前有许多好用的 <a href="https://www.jianshu.com/p/d4e331770e60" target="_blank" rel="noopener">Markdown 编辑工具</a>，有的收费，有的免费，相对而言收费工具的体验较好。Markdown 文件的后缀名为<code>.md</code>，对于一名程序员来说，最友好的Markdown 编辑界面当然是 IDE 自带的 Markdown 编辑插件。<br>在 <a href="https://www.jetbrains.com/pycharm/" target="_blank" rel="noopener">Pycharm</a> 中添加 Markdown 插件的步骤如下，<code>File-&gt;Settings-&gt;Plugins-&gt;Install JetBrains Plugins-&gt;输入Markdown-&gt;选择插件-&gt;Install-&gt;安装完成后重启PyCharm</code>。编辑界面如下图所示，黑色背景，支持预览，所见即所得。</p><div align="center"><img src="/2018/12/01/hello-world/pycharm_markdown.png" alt="Pycharm Markdown 插件编辑效果图" width="500" height="300"><p style="font-size:90%;color:#00CD00">Pycharm Markdown 插件编辑效果图</p></div> <p>在 VSCodescode 中支持 Markdown 语法，只需要下载 Markdown 预览插件即可。在 VSCode 中添加插件的步骤如下，选择左边栏第四个图标 <code>Extensions</code>，在输入框搜索 <code>Markdown Preview Enhanced</code>，安装成功后重启 VSCode。编辑界面如下图所示，黑色背景，支持预览，所见即所得。</p><div align="center"><img src="/2018/12/01/hello-world/vscode_markdown.png" alt="VSCode Markdown 插件编辑效果图" width="500" height="300"><p style="font-size:90%;color:#00CD00">VSCode Markdown 插件编辑效果图</p></div> ]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo 博客 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>为什么写博客</title>
      <link href="/2018/11/28/why-blog/"/>
      <url>/2018/11/28/why-blog/</url>
      
        <content type="html"><![CDATA[<blockquote><p><strong><em>刘未鹏 —— 《暗时间》</em></strong><br>写一个博客有很多的好处，却没有任何明显的坏处。更明确的说：用博客的形式来记录下你有价值的思考，会带来很多好处，却没有任何明显的坏处。写一个长期的价值博客最大的几点好处:  </p><ol><li>能够交到很多志同道合的朋友。 书写是为了更好地思考。 </li><li>“教”是最好的“学”。如果一件事情你不能讲清楚，十有八九你还没有完全理解。</li><li>激励你去持续学习和思考。</li><li>学会持之以恒地做一件事情。</li><li>一个长期的价值博客是一份很好的简历。</li></ol></blockquote><p>谨以博客记录算法菜鸟的“攻城狮”之路。</p>]]></content>
      
      
      
    </entry>
    
  
  
</search>
